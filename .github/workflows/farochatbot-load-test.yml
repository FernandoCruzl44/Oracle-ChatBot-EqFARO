name: JMeter Load Test - Faro Chatbot

on:
  workflow_dispatch:
    inputs:
      users:
        description: "Number of concurrent users"
        required: true
        default: "10"
      rampup:
        description: "Ramp-up period in seconds"
        required: true
        default: "30"
      duration:
        description: "Test duration in seconds"
        required: true
        default: "300"
  schedule:
    - cron: "0 0 * * *"

jobs:
  load_test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Create JMeter Test Plan
        run: |
          mkdir -p tests
          cat > tests/farochatbot_test.jmx << 'EOL'
          <?xml version="1.0" encoding="UTF-8"?>
          <jmeterTestPlan version="1.2" properties="5.0" jmeter="5.4.1">
            <hashTree>
              <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="Faro Chatbot Load Test" enabled="true">
                <stringProp name="TestPlan.comments">Load test for farochatbot.duckdns.org</stringProp>
                <boolProp name="TestPlan.functional_mode">false</boolProp>
                <boolProp name="TestPlan.tearDown_on_shutdown">true</boolProp>
                <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
                <elementProp name="TestPlan.user_defined_variables" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments" testname="User Defined Variables" enabled="true">
                  <collectionProp name="Arguments.arguments"/>
                </elementProp>
                <stringProp name="TestPlan.user_define_classpath"></stringProp>
              </TestPlan>
              <hashTree>
                <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="Concurrent Users" enabled="true">
                  <stringProp name="ThreadGroup.on_sample_error">continue</stringProp>
                  <elementProp name="ThreadGroup.main_controller" elementType="LoopController" guiclass="LoopControlPanel" testclass="LoopController" testname="Loop Controller" enabled="true">
                    <boolProp name="LoopController.continue_forever">false</boolProp>
                    <intProp name="LoopController.loops">-1</intProp>
                  </elementProp>
                  <stringProp name="ThreadGroup.num_threads">${__P(users,10)}</stringProp>
                  <stringProp name="ThreadGroup.ramp_time">${__P(rampup,30)}</stringProp>
                  <boolProp name="ThreadGroup.scheduler">true</boolProp>
                  <stringProp name="ThreadGroup.duration">${__P(duration,300)}</stringProp>
                  <stringProp name="ThreadGroup.delay">0</stringProp>
                  <boolProp name="ThreadGroup.same_user_on_next_iteration">true</boolProp>
                </ThreadGroup>
                <hashTree>
                  <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="HTTP Request - Homepage" enabled="true">
                    <elementProp name="HTTPsampler.Arguments" elementType="Arguments" guiclass="HTTPArgumentsPanel" testclass="Arguments" testname="User Defined Variables" enabled="true">
                      <collectionProp name="Arguments.arguments"/>
                    </elementProp>
                    <stringProp name="HTTPSampler.domain">farochatbot.duckdns.org</stringProp>
                    <stringProp name="HTTPSampler.port"></stringProp>
                    <stringProp name="HTTPSampler.protocol">http</stringProp>
                    <stringProp name="HTTPSampler.contentEncoding"></stringProp>
                    <stringProp name="HTTPSampler.path">/</stringProp>
                    <stringProp name="HTTPSampler.method">GET</stringProp>
                    <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
                    <boolProp name="HTTPSampler.auto_redirects">false</boolProp>
                    <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
                    <boolProp name="HTTPSampler.DO_MULTIPART_POST">false</boolProp>
                    <stringProp name="HTTPSampler.embedded_url_re"></stringProp>
                    <stringProp name="HTTPSampler.connect_timeout">5000</stringProp>
                    <stringProp name="HTTPSampler.response_timeout">30000</stringProp>
                  </HTTPSamplerProxy>
                  <hashTree>
                    <UniformRandomTimer guiclass="UniformRandomTimerGui" testclass="UniformRandomTimer" testname="User Think Time" enabled="true">
                      <stringProp name="ConstantTimer.delay">1000</stringProp>
                      <stringProp name="RandomTimer.range">2000</stringProp>
                    </UniformRandomTimer>
                    <hashTree/>
                  </hashTree>
                  <ConstantThroughputTimer guiclass="ConstantThroughputTimerGui" testclass="ConstantThroughputTimer" testname="Constant Throughput Timer" enabled="true">
                    <doubleProp>
                      <name>throughput</name>
                      <value>60.0</value>
                      <savedValue>0.0</savedValue>
                    </doubleProp>
                    <intProp name="calcMode">0</intProp>
                  </ConstantThroughputTimer>
                  <hashTree/>
                  <ResultCollector guiclass="ViewResultsFullVisualizer" testclass="ResultCollector" testname="View Results Tree" enabled="true">
                    <boolProp name="ResultCollector.error_logging">false</boolProp>
                    <objProp>
                      <name>saveConfig</name>
                      <value class="SampleSaveConfiguration">
                        <time>true</time>
                        <latency>true</latency>
                        <timestamp>true</timestamp>
                        <success>true</success>
                        <label>true</label>
                        <code>true</code>
                        <message>true</message>
                        <threadName>true</threadName>
                        <dataType>true</dataType>
                        <encoding>false</encoding>
                        <assertions>true</assertions>
                        <subresults>true</subresults>
                        <responseData>false</responseData>
                        <samplerData>false</samplerData>
                        <xml>false</xml>
                        <fieldNames>true</fieldNames>
                        <responseHeaders>false</responseHeaders>
                        <requestHeaders>false</requestHeaders>
                        <responseDataOnError>false</responseDataOnError>
                        <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                        <assertionsResultsToSave>0</assertionsResultsToSave>
                        <bytes>true</bytes>
                        <sentBytes>true</sentBytes>
                        <url>true</url>
                        <threadCounts>true</threadCounts>
                        <idleTime>true</idleTime>
                        <connectTime>true</connectTime>
                      </value>
                    </objProp>
                    <stringProp name="filename"></stringProp>
                  </ResultCollector>
                  <hashTree/>
                  <ResultCollector guiclass="SummaryReport" testclass="ResultCollector" testname="Summary Report" enabled="true">
                    <boolProp name="ResultCollector.error_logging">false</boolProp>
                    <objProp>
                      <name>saveConfig</name>
                      <value class="SampleSaveConfiguration">
                        <time>true</time>
                        <latency>true</latency>
                        <timestamp>true</timestamp>
                        <success>true</success>
                        <label>true</label>
                        <code>true</code>
                        <message>true</message>
                        <threadName>true</threadName>
                        <dataType>true</dataType>
                        <encoding>false</encoding>
                        <assertions>true</assertions>
                        <subresults>true</subresults>
                        <responseData>false</responseData>
                        <samplerData>false</samplerData>
                        <xml>false</xml>
                        <fieldNames>true</fieldNames>
                        <responseHeaders>false</responseHeaders>
                        <requestHeaders>false</requestHeaders>
                        <responseDataOnError>false</responseDataOnError>
                        <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                        <assertionsResultsToSave>0</assertionsResultsToSave>
                        <bytes>true</bytes>
                        <sentBytes>true</sentBytes>
                        <url>true</url>
                        <threadCounts>true</threadCounts>
                        <idleTime>true</idleTime>
                        <connectTime>true</connectTime>
                      </value>
                    </objProp>
                    <stringProp name="filename"></stringProp>
                  </ResultCollector>
                  <hashTree/>
                  <ResultCollector guiclass="GraphVisualizer" testclass="ResultCollector" testname="Graph Results" enabled="true">
                    <boolProp name="ResultCollector.error_logging">false</boolProp>
                    <objProp>
                      <name>saveConfig</name>
                      <value class="SampleSaveConfiguration">
                        <time>true</time>
                        <latency>true</latency>
                        <timestamp>true</timestamp>
                        <success>true</success>
                        <label>true</label>
                        <code>true</code>
                        <message>true</message>
                        <threadName>true</threadName>
                        <dataType>true</dataType>
                        <encoding>false</encoding>
                        <assertions>true</assertions>
                        <subresults>true</subresults>
                        <responseData>false</responseData>
                        <samplerData>false</samplerData>
                        <xml>false</xml>
                        <fieldNames>true</fieldNames>
                        <responseHeaders>false</responseHeaders>
                        <requestHeaders>false</requestHeaders>
                        <responseDataOnError>false</responseDataOnError>
                        <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                        <assertionsResultsToSave>0</assertionsResultsToSave>
                        <bytes>true</bytes>
                        <sentBytes>true</sentBytes>
                        <url>true</url>
                        <threadCounts>true</threadCounts>
                        <idleTime>true</idleTime>
                        <connectTime>true</connectTime>
                      </value>
                    </objProp>
                    <stringProp name="filename"></stringProp>
                  </ResultCollector>
                  <hashTree/>
                </hashTree>
              </hashTree>
            </hashTree>
          </jmeterTestPlan>
          EOL

      - name: Run JMeter Tests for Faro Chatbot
        uses: rbhadti94/apache-jmeter-action@v0.5.0
        with:
          testFilePath: tests/farochatbot_test.jmx
          outputReportsFolder: reports/
          args: >-
            --loglevel INFO
            -Jusers=${{ github.event.inputs.users || '10' }}
            -Jrampup=${{ github.event.inputs.rampup || '30' }}
            -Jduration=${{ github.event.inputs.duration || '300' }}

      - name: Generate JMeter Report
        run: |
          mkdir -p results
          ls -la reports/
          # If JTL file exists, use it to generate HTML report
          if [ -f reports/*.jtl ]; then
            # Find the first JTL file
            JTL_FILE=$(find reports/ -name "*.jtl" | head -n 1)
            echo "Found JTL file: $JTL_FILE"
            
            # Create a timestamp for report folder
            TIMESTAMP=$(date +%Y%m%d%H%M%S)
            
            # Use the JMeter report generator to create HTML report
            jmeter -g $JTL_FILE -o results/html-report-$TIMESTAMP
          else
            echo "No JTL file found in reports/ directory"
            ls -la reports/
          fi
        continue-on-error: true

      - name: Upload JMeter test results
        uses: actions/upload-artifact@v3
        with:
          name: jmeter-test-results
          path: |
            reports/
            results/

      - name: Create Test Summary
        run: |
          echo "# Faro Chatbot Load Test Results" > summary.md
          echo "" >> summary.md
          echo "## Test Configuration" >> summary.md
          echo "- Target: http://farochatbot.duckdns.org/" >> summary.md
          echo "- Concurrent Users: ${{ github.event.inputs.users || '10' }}" >> summary.md
          echo "- Ramp-up Period: ${{ github.event.inputs.rampup || '30' }} seconds" >> summary.md
          echo "- Test Duration: ${{ github.event.inputs.duration || '300' }} seconds" >> summary.md
          echo "" >> summary.md
          echo "## Summary" >> summary.md

          # Try to extract information from the JTL file if it exists
          if [ -f reports/*.jtl ]; then
            JTL_FILE=$(find reports/ -name "*.jtl" | head -n 1)
            echo "Summary information extracted from $JTL_FILE:" >> summary.md
            
            # Count total requests
            TOTAL_REQUESTS=$(grep -c "<sample" $JTL_FILE)
            echo "- Total Requests: $TOTAL_REQUESTS" >> summary.md
            
            # Count errors
            ERROR_REQUESTS=$(grep "<sample" $JTL_FILE | grep "s=\"false\"" | wc -l)
            echo "- Failed Requests: $ERROR_REQUESTS" >> summary.md
            
            # Calculate error rate
            if [ $TOTAL_REQUESTS -gt 0 ]; then
              ERROR_RATE=$(echo "scale=2; $ERROR_REQUESTS * 100 / $TOTAL_REQUESTS" | bc)
              echo "- Error Rate: $ERROR_RATE%" >> summary.md
            fi
            
            # Extract average response time
            AVG_RESPONSE=$(grep "<sample" $JTL_FILE | awk -F'"' '{sum+=$8; count++} END {print sum/count}')
            echo "- Average Response Time: $AVG_RESPONSE ms" >> summary.md
          else
            echo "No JTL results file found. Check the uploaded artifacts for detailed results." >> summary.md
          fi
        continue-on-error: true

      - name: Upload Summary
        uses: actions/upload-artifact@v3
        with:
          name: test-summary
          path: summary.md
